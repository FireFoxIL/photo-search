{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 14) # (w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showInRow(list_of_images, titles = None, disable_ticks = False):\n",
    "    count = len(list_of_images)\n",
    "    for idx in range(count):\n",
    "        subplot = plt.subplot(1, count, idx+1)\n",
    "        if titles is not None:\n",
    "            subplot.set_title(titles[idx])\n",
    "          \n",
    "        img = list_of_images[idx]\n",
    "        cmap = 'gray' if (len(img.shape) == 2 or img.shape[2] == 1) else None\n",
    "        subplot.imshow(img, cmap=cmap)\n",
    "        if disable_ticks:\n",
    "            plt.xticks([]), plt.yticks([])\n",
    "    plt.show()\n",
    "\n",
    "def draw_faces(img, faces, verbose=True):\n",
    "    res_img = img.copy()\n",
    "    \n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(res_img, (x, y), (x+w, y+h), (0, 255, 0), 8)\n",
    "    if verbose:\n",
    "        plt.imshow(res_img)\n",
    "        plt.show()\n",
    "#     return res_img\n",
    "\n",
    "def extract_faces(img, faces):\n",
    "    res_imgs = []\n",
    "    for (x, y, w, h) in faces:\n",
    "        res_imgs.append(img[y:y+h, x:x+w])\n",
    "    return res_imgs\n",
    "\n",
    "def dlib_rect_to_bb(rect):\n",
    "    \"\"\"Take a bounding predicted by dlib and convert it\n",
    "    to the format (x, y, w, h) as we would normally do\n",
    "    with OpenCV\n",
    "    \n",
    "    Taken from https://github.com/jrosebr1/imutils/blob/master/imutils/face_utils/helpers.py\n",
    "    \"\"\"\n",
    "    return rect_to_bb((rect.left(), rect.top(), rect.right(), rect.bottom()))\n",
    "\n",
    "def rect_to_bb(rect):\n",
    "    x1, y1, x2, y2 = rect\n",
    "    return (x1, y1, x2-x1, y2-y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(path):\n",
    "    with open(path) as input_file:\n",
    "        return json.loads(input_file)\n",
    "\n",
    "def write_json(obj, path, default=None):\n",
    "    os.makedirs(os.path.split(path)[0], exist_ok=True)\n",
    "    with open(path, 'w') as output_file:\n",
    "        json.dump(obj, output_file, default=default, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_image, load_images, ImageLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_path = 'face_detection_res'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_numpy_datatypes(o):\n",
    "    if isinstance(o, np.int64) or isinstance(o, np.int32):\n",
    "        return int(o)\n",
    "    raise TypeError\n",
    "\n",
    "\n",
    "def test_detector(detector, data, res_path='res.json', verbose=False):\n",
    "    bboxes = {}\n",
    "    for img_path, img in tqdm_notebook(data, desc='Detect faces'):\n",
    "        faces = detector.detect(img)\n",
    "        if isinstance(faces, tuple):\n",
    "            faces = []\n",
    "        elif isinstance(faces, np.ndarray):\n",
    "            faces = faces.tolist()\n",
    "        bboxes[img_path] = faces\n",
    "        if verbose:\n",
    "            draw_faces(img[:, :, ::-1], faces)\n",
    "    write_json(bboxes, res_path, default=convert_numpy_datatypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ['data/test_img.jpg']\n",
    "data = [(img_path, load_image(img_path)) for img_path in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "409"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = os.path.join('data', 'FaceDetectionDataset')\n",
    "data = ImageLoader(data_path, return_full_path=False)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haar's feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cascPath = 'data/haarcascade.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HaarDetector:\n",
    "    \"\"\"Haar feature selection.\"\"\"\n",
    "    def __init__(self, cascPath):\n",
    "        self.model = cv2.CascadeClassifier(cascPath)\n",
    "    \n",
    "    def detect(self, img):\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        return self.model.detectMultiScale(\n",
    "            gray_img,\n",
    "            scaleFactor=1.2,\n",
    "            minNeighbors=7,\n",
    "            minSize=(20, 20),\n",
    "            flags = cv2.CASCADE_SCALE_IMAGE\n",
    "        )\n",
    "haar_detector = HaarDetector(cascPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db0bbbf604eb4700a096a6845570e987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Detect faces', max=409, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_detector(haar_detector, data, res_path=os.path.join(res_path, 'haar.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "\n",
    "class HOGDetector:\n",
    "    \"\"\"HOGDetector\"\"\"\n",
    "    def __init__(self):\n",
    "        self.model = dlib.get_frontal_face_detector()\n",
    "    \n",
    "    def detect(self, img):\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        face_rects = self.model(gray_img)\n",
    "        return [dlib_rect_to_bb(face_rect) for face_rect in face_rects]\n",
    "\n",
    "hog_detector = HOGDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc1df3d5cb574a3e8d084ddcdd96ed99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Detect faces', max=409, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_detector(hog_detector,\n",
    "              data, \n",
    "              res_path=os.path.join(res_path, 'hog.json'),\n",
    "              verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN (based on ResNet-34)\n",
    "https://github.com/davisking/dlib-models\n",
    "\n",
    "Doesn't work, caches results, which fills 8 gigabytes of RAM after processing 12 pictures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "\n",
    "class ResNetDetector:\n",
    "    \"ResNetDetector\"\n",
    "    def __init__(self, path_to_weights):\n",
    "        self.model = dlib.cnn_face_detection_model_v1(path_to_weights)\n",
    "    \n",
    "    def detect(self, img):\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        face_rects = self.model(gray_img, 1)\n",
    "        face_rects = [rect.rect for rect in face_rects]\n",
    "        return [dlib_rect_to_bb(face_rect) for face_rect in face_rects]\n",
    "\n",
    "resnet_detector = ResNetDetector('data/model_weights/mmod_human_face_detector.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlib.DLIB_USE_CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_detector(resnet_detector, data, res_path=os.path.join(res_path, 'resnet.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cvlib\n",
    "https://www.cvlib.net/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cvlib\n",
    "\n",
    "class CVLibDetector:\n",
    "    \"CVLibDetector\"\n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n",
    "    def detect(self, img):\n",
    "        face_rects, confidences = cvlib.detect_face(img)\n",
    "        faces = [rect_to_bb(face_rect) for face_rect in face_rects]\n",
    "        return faces\n",
    "\n",
    "cvlib_detector = CVLibDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "738d79bc14434ecab29498417ffe8680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Detect faces', max=409, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_detector(cvlib_detector, data, res_path=os.path.join(res_path, 'cvlib.json'), verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mtcnn.mtcnn import MTCNN\n",
    "model = MTCNN()\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MTCNNDetector:\n",
    "    \"\"\"MTCNNDetector\"\"\"\n",
    "    def __init__(self):\n",
    "        self.model = MTCNN()\n",
    "    \n",
    "    def detect(self, img):\n",
    "        faces = self.model.detect_faces(img)\n",
    "        faces = [x['box'] for x in faces]\n",
    "        return faces\n",
    "\n",
    "mtcnn_detector = MTCNNDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ce9eabb68ce4d29b0e414fb80b818c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Detect faces', max=409, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_detector(mtcnn_detector,\n",
    "              data,\n",
    "              res_path=os.path.join(res_path, 'mtcnn.json'),\n",
    "              verbose=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
